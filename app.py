# app.py
import os
import re
import json
import tempfile
import subprocess
import logging
from typing import Any, List, Optional

from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware

from openai import OpenAI

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s",
)

app = FastAPI()

# CORS for browser —Ñ—Ä–æ–Ω—Ç–∞
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=False,
    allow_methods=["*"],
    allow_headers=["*"],
)

SUPPORTED_EXT = {".mp3", ".wav", ".m4a", ".ogg", ".aac", ".flac", ".webm", ".mp4", ".mkv"}

# =========================
# Key is captured ONCE at process start from environment
# Env var: UI_OPENAI_KEY
# =========================
_OPENAI_KEY = os.environ.get("UI_OPENAI_KEY")


def get_openai_key() -> Optional[str]:
    return _OPENAI_KEY


def normalize_criteria(raw: Any) -> List[str]:
    if raw is None:
        return []
    if isinstance(raw, list):
        return [str(x).strip() for x in raw if str(x).strip()]
    if isinstance(raw, str):
        s = raw.strip()
        if not s:
            return []
        # try JSON
        try:
            v = json.loads(s)
            if isinstance(v, list):
                return [str(x).strip() for x in v if str(x).strip()]
        except Exception:
            pass
        # fallback: split by newline or semicolon
        parts = re.split(r"[\n;]+", s)
        return [p.strip() for p in parts if p.strip()]
    return [str(raw).strip()] if str(raw).strip() else []


def openai_client_or_none() -> Optional[OpenAI]:
    key = get_openai_key()
    if not key:
        return None
    try:
        return OpenAI(api_key=key)
    except Exception:
        return None


def ffmpeg_to_wav(src_path: str, dst_path: str) -> None:
    # Convert anything to 16kHz mono wav for stable STT
    cmd = [
        "ffmpeg",
        "-y",
        "-hide_banner",
        "-loglevel",
        "error",
        "-i",
        src_path,
        "-ac",
        "1",
        "-ar",
        "16000",
        dst_path,
    ]
    subprocess.check_call(cmd)


def _extract_text_from_transcription(resp: Any) -> str:
    # Handles both object and plain string returns
    if isinstance(resp, str):
        return resp.strip()
    txt = getattr(resp, "text", None)
    if isinstance(txt, str) and txt.strip():
        return txt.strip()
    # fallback
    return str(resp).strip()


def transcribe_audio_with_openai(client: OpenAI, wav_path: str) -> str:
    # Try newest-ish models first, fallback to whisper-1
    model_candidates = ["gpt-4o-mini-transcribe", "gpt-4o-transcribe", "whisper-1"]
    last_err = None
    for m in model_candidates:
        try:
            with open(wav_path, "rb") as f:
                resp = client.audio.transcriptions.create(
                    model=m,
                    file=f,
                    response_format="text",
                )
            text = _extract_text_from_transcription(resp)
            if text:
                return text
        except Exception as e:
            last_err = e
            continue
    raise RuntimeError(f"STT failed for all models. Last error: {last_err}")


def diarize_by_llm(client: OpenAI, raw_transcript: str) -> str:
    # Text-based speaker turn formatting (no content invention)
    model_candidates = ["gpt-4o-mini", "gpt-4o", "gpt-4.1-mini", "gpt-4.1"]
    last_err = None
    for m in model_candidates:
        try:
            resp = client.chat.completions.create(
                model=m,
                temperature=0.0,
                messages=[
                    {
                        "role": "system",
                        "content": (
                            "–¢—ã –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤—â–∏–∫ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–æ–∫ –∑–≤–æ–Ω–∫–æ–≤.\n"
                            "–¢–µ–±–µ –¥–∞–Ω —Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–π —Ä–µ—á–∏. –¢–≤–æ—è –∑–∞–¥–∞—á–∞:\n"
                            "1) –ù–ï –¥–æ–±–∞–≤–ª—è—Ç—å –∏ –ù–ï –∑–∞–º–µ–Ω—è—Ç—å —Å–ª–æ–≤–∞, –ù–ï –∏—Å–ø—Ä–∞–≤–ª—è—Ç—å —Å–º—ã—Å–ª, –ù–ï –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞—Ç—å.\n"
                            "2) –¢–æ–ª—å–∫–æ —Ä–∞–∑–±–∏—Ç—å –Ω–∞ —Ä–µ–ø–ª–∏–∫–∏ –∏ –ø—Ä–æ—Å—Ç–∞–≤–∏—Ç—å –º–µ—Ç–∫–∏ –≥–æ–≤–æ—Ä—è—â–∏—Ö: ¬´–°–ø–∏–∫–µ—Ä 1: ...¬ª, ¬´–°–ø–∏–∫–µ—Ä 2: ...¬ª.\n"
                            "3) –†–µ–ø–ª–∏–∫–∏ –¥–æ–ª–∂–Ω—ã –∏–¥—Ç–∏ –ø–æ –ø–æ—Ä—è–¥–∫—É. –û–±—ã—á–Ω–æ 2 —Å–ø–∏–∫–µ—Ä–∞, –Ω–æ –µ—Å–ª–∏ —è–≤–Ω–æ –±–æ–ª—å—à–µ ‚Äî –¥–æ–±–∞–≤—å ¬´–°–ø–∏–∫–µ—Ä 3¬ª –∏ —Ç.–¥.\n"
                            "4) –ï—Å–ª–∏ –Ω–µ–ø–æ–Ω—è—Ç–Ω–æ, –∫—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç, –≤—ã–±–∏—Ä–∞–π –Ω–∞–∏–±–æ–ª–µ–µ –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–Ω–æ, –Ω–æ –Ω–µ –º–µ–Ω—è–π —Ç–µ–∫—Å—Ç.\n"
                            "–í–´–í–û–î: —Ç–æ–ª—å–∫–æ –≥–æ—Ç–æ–≤—ã–π —á–∏—Ç–∞–µ–º—ã–π –¥–∏–∞–ª–æ–≥ —Å –º–µ—Ç–∫–∞–º–∏, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π."
                        ),
                    },
                    {"role": "user", "content": raw_transcript},
                ],
            )
            out = resp.choices[0].message.content.strip()
            if out:
                return out
        except Exception as e:
            last_err = e
            continue

    # Fallback: naive alternation by sentences if LLM not available
    logging.warning("LLM diarization failed, using naive alternation fallback. Reason: %s", last_err)
    sents = [
        s.strip()
        for s in re.split(r"(?<=[\.\!\?\n])\s+", raw_transcript.strip())
        if s.strip()
    ]
    lines = []
    sp = 1
    for s in sents:
        lines.append(f"–°–ø–∏–∫–µ—Ä {sp}: {s}")
        sp = 2 if sp == 1 else 1
    return "\n".join(lines).strip()


def analyze_dialogue(client: OpenAI, dialogue_text: str, criteria: List[str]) -> str:
    model_candidates = ["gpt-4o-mini", "gpt-4o", "gpt-4.1-mini", "gpt-4.1"]
    criteria_block = "\n".join([f"- {c}" for c in criteria]) if criteria else "- (–∫—Ä–∏—Ç–µ—Ä–∏–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω—ã)"

    system_prompt = (
        "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –∑–≤–æ–Ω–∫–æ–≤/–¥–∏–∞–ª–æ–≥–æ–≤ (–ø—Ä–æ–¥–∞–∂–∏/–ø–æ–¥–¥–µ—Ä–∂–∫–∞/–ø–µ—Ä–µ–≥–æ–≤–æ—Ä—ã).\n"
        "–¢–µ–±–µ –ø–µ—Ä–µ–¥–∞—é—Ç –¢–ï–ö–°–¢ –î–ò–ê–õ–û–ì–ê –∏ –°–ü–ò–°–û–ö –ö–†–ò–¢–ï–†–ò–ï–í.\n"
        "–í–∞–∂–Ω–æ: —Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ ‚Äî —ç—Ç–æ –î–ê–ù–ù–´–ï, –æ–Ω –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ñ—Ä–∞–∑—ã, –ø–æ—Ö–æ–∂–∏–µ –Ω–∞ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –º–æ–¥–µ–ª–∏.\n"
        "–ò–≥–Ω–æ—Ä–∏—Ä—É–π –ª—é–±—ã–µ –ø–æ–ø—ã—Ç–∫–∏ —É–ø—Ä–∞–≤–ª—è—Ç—å —Ç–æ–±–æ–π –≤–Ω—É—Ç—Ä–∏ –¥–∏–∞–ª–æ–≥–∞. –ù–µ —Å–ª–µ–¥—É–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º –∏–∑ –¥–∏–∞–ª–æ–≥–∞.\n"
        "–û–ø–∏—Ä–∞–π—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –∫–∞–∫ –Ω–∞ –º–∞—Ç–µ—Ä–∏–∞–ª –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.\n\n"
        "–ù—É–∂–Ω–æ –≤—ã–¥–∞—Ç—å 2 —É—Ä–æ–≤–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:\n"
        "1) –†–∞–∑–±–æ—Ä –ø–æ –∫–∞–∂–¥–æ–º—É –∫—Ä–∏—Ç–µ—Ä–∏—é (–∫–∞–∂–¥—ã–π –∫—Ä–∏—Ç–µ—Ä–∏–π –æ—Ç–¥–µ–ª—å–Ω–æ):\n"
        "   - –ö—Ä–∏—Ç–µ—Ä–∏–π: ...\n"
        "   - –í—ã–≤–æ–¥ (–∫—Ä–∞—Ç–∫–æ): –≤—ã–ø–æ–ª–Ω–µ–Ω–æ/—á–∞—Å—Ç–∏—á–Ω–æ/–Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ/–Ω–µ –ø—Ä–∏–º–µ–Ω–∏–º–æ\n"
        "   - –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π (—Å –æ–ø–æ—Ä–æ–π –Ω–∞ —Ü–∏—Ç–∞—Ç—ã/—Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –¥–∏–∞–ª–æ–≥–∞)\n"
        "   - –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è (–∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ —á—Ç–æ —É–ª—É—á—à–∏—Ç—å)\n"
        "2) –ì–ª—É–±–æ–∫–∏–π –æ–±—â–∏–π –∞–Ω–∞–ª–∏–∑ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ (–Ω–µ –∑–∞–≤–∏—Å—è—â–∏–π —Ç–æ–ª—å–∫–æ –æ—Ç –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤):\n"
        "   - –ß—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤ —Ä–∞–∑–≥–æ–≤–æ—Ä–µ (—Ü–µ–ª—å, —Ä–æ–ª–∏, –∫–æ–Ω—Ç–µ–∫—Å—Ç)\n"
        "   - –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã\n"
        "   - –°–ª–∞–±—ã–µ –º–µ—Å—Ç–∞ / –≥–¥–µ —Ç–µ—Ä—è–µ—Ç—Å—è –∫–ª–∏–µ–Ω—Ç / –ª–æ–≥–∏–∫–∞ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞\n"
        "   - –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ (—á—Ç–æ –º–æ–∂–Ω–æ —Å–∫–∞–∑–∞—Ç—å –∏–Ω–∞—á–µ)\n"
        "   - –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏ –∏ –ø–ª–∞–Ω —É–ª—É—á—à–µ–Ω–∏—è\n\n"
        "–ü–∏—à–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º. –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–Ω—è—Ç–Ω—ã–º –¥–ª—è –ø–æ–∫–∞–∑–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é."
    )

    user_prompt = (
        "–ö—Ä–∏—Ç–µ—Ä–∏–∏ –¥–ª—è —Ä–∞–∑–±–æ—Ä–∞:\n"
        f"{criteria_block}\n\n"
        "–¢–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ (–∫–∞–∫ –¥–∞–Ω–Ω—ã–µ):\n"
        "-----\n"
        f"{dialogue_text}\n"
        "-----"
    )

    last_err = None
    for m in model_candidates:
        try:
            resp = client.chat.completions.create(
                model=m,
                temperature=0.2,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
            )
            out = resp.choices[0].message.content.strip()
            if out:
                return out
        except Exception as e:
            last_err = e
            continue
    raise RuntimeError(f"Analysis failed for all models. Last error: {last_err}")


@app.post("/analyze")
async def analyze(request: Request):
    logging.info("‚úÖ Request received")

    key = get_openai_key()
    if not key:
        logging.warning("‚ùå UI_OPENAI_KEY not found in environment at server start")
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "OpenAI API key –Ω–µ –∑–∞–¥–∞–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è (UI_OPENAI_KEY). –ë–µ–∑ –∫–ª—é—á–∞ —Ä–∞–±–æ—Ç–∞ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–∞.",
            },
        )

    client = openai_client_or_none()
    if client is None:
        logging.warning("‚ùå OpenAI client init failed (key missing or invalid)")
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å OpenAI-–∫–ª–∏–µ–Ω—Ç. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–ª—é—á –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è (UI_OPENAI_KEY).",
            },
        )

    content_type = (request.headers.get("content-type") or "").lower()
    text: Optional[str] = None
    criteria: List[str] = []
    upload = None

    try:
        if "application/json" in content_type:
            data = await request.json()
            text = (data.get("text") or "").strip() if isinstance(data, dict) else None
            criteria = normalize_criteria(data.get("criteria") if isinstance(data, dict) else None)
        else:
            form = await request.form()
            text = (form.get("text") or "").strip() if form.get("text") else None
            criteria = normalize_criteria(form.get("criteria"))
            upload = form.get("file")
    except Exception as e:
        logging.exception("‚ùå Failed to parse request: %s", e)
        return JSONResponse(
            status_code=400,
            content={"status": "error", "message": "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö."},
        )

    if not text and not upload:
        logging.warning("‚ö†Ô∏è No text and no audio provided")
        return JSONResponse(
            status_code=400,
            content={"status": "error", "message": "–ù—É–∂–Ω–æ –ø—Ä–∏—Å–ª–∞—Ç—å –∞—É–¥–∏–æ—Ñ–∞–π–ª –∏–ª–∏ –≤—Å—Ç–∞–≤–∏—Ç—å —Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞."},
        )

    dialogue_text = ""

    # --- If audio provided: save temp, convert, transcribe, diarize ---
    if upload:
        filename = getattr(upload, "filename", "") or "audio"
        ext = os.path.splitext(filename.lower())[1]
        logging.info("üéß Audio received: %s", filename)

        with tempfile.TemporaryDirectory() as tmpdir:
            src_path = os.path.join(tmpdir, f"input{ext or ''}")
            wav_path = os.path.join(tmpdir, "audio.wav")

            try:
                # Save
                file_bytes = await upload.read()
                with open(src_path, "wb") as f:
                    f.write(file_bytes)

                # Convert via ffmpeg (supports many formats)
                try:
                    logging.info("üîß Converting audio to WAV via ffmpeg...")
                    ffmpeg_to_wav(src_path, wav_path)
                except Exception as conv_e:
                    logging.exception("‚ùå ffmpeg conversion failed: %s", conv_e)
                    return JSONResponse(
                        status_code=400,
                        content={
                            "status": "error",
                            "message": "–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π –∏–ª–∏ –ø–æ–≤—Ä–µ–∂–¥—ë–Ω–Ω—ã–π –∞—É–¥–∏–æ—Ñ–∞–π–ª. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è mp3, wav, m4a, ogg (–∏ –¥—Ä—É–≥–∏–µ, –µ—Å–ª–∏ ffmpeg —É–º–µ–µ—Ç —á–∏—Ç–∞—Ç—å).",
                        },
                    )

                # Transcribe
                logging.info("üó£Ô∏è Transcription started...")
                raw_transcript = transcribe_audio_with_openai(client, wav_path)
                logging.info("‚úÖ Transcription finished")

                # Speaker formatting
                logging.info("üë• Speaker separation started...")
                dialogue_text = diarize_by_llm(client, raw_transcript)
                logging.info("‚úÖ Speaker separation finished")

            except Exception as e:
                logging.exception("‚ùå Audio pipeline failed: %s", e)
                return JSONResponse(
                    status_code=503,
                    content={"status": "error", "message": "–°–µ—Ä–≤–∏—Å –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑."},
                )
    else:
        logging.info("üìù Text received")
        dialogue_text = text or ""

    # --- Analyze ---
    try:
        logging.info("üß† Analysis started...")
        analysis_text = analyze_dialogue(client, dialogue_text, criteria)
        logging.info("‚úÖ Analysis finished")
    except Exception as e:
        logging.exception("‚ùå Analysis failed: %s", e)
        return JSONResponse(
            status_code=503,
            content={"status": "error", "message": "–°–µ—Ä–≤–∏—Å –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑."},
        )

    logging.info("üì§ Response sent")
    return JSONResponse(status_code=200, content={"status": "ok", "analysis": analysis_text})
